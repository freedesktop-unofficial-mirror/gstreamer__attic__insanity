#!/usr/bin/env python

# GStreamer QA system
#
#       insanity-dumpresults-json
#        - Output vaguely lava-dashboard compatible json.
#
# Copyright (c) 2008, Edward Hervey <bilboed@bilboed.com>
# Copyright (c) 2011, Collabora Ltd. <david.laban@collabora.co.uk>
#
# This program is free software; you can redistribute it and/or
# modify it under the terms of the GNU Lesser General Public
# License as published by the Free Software Foundation; either
# version 2.1 of the License, or (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
# Lesser General Public License for more details.
#
# You should have received a copy of the GNU Lesser General Public
# License along with this program; if not, write to the
# Free Software Foundation, Inc., 59 Temple Place - Suite 330,
# Boston, MA 02111-1307, USA.

"""
Dumps the results of a test results DB
"""

import sys
import time
from argparse import ArgumentParser
from insanity.log import initLogging, warning
import simplejson

# Since the dashboard model puts a limit on the length of attribute keys,
# we may need to truncate them.
MAX_ATTR_LEN = 32

def printTestRunInfo(db, testrunid, verbose=False):
    # id , date, nbtests, client
    cid, starttime, stoptime = db.getTestRun(testrunid)
    softname, clientname, clientuser = db.getClientInfoForTestRun(testrunid)
    nbtests = db.getNbTestsForTestrun(testrunid)
    nbfailed = db.getNbTestsForTestrun(testrunid, failedonly=True)
    print "[% 3d]\tDate:%s\tNbTests:% 5d\tFailed:% 5d\tClient: %s/%s/%s" % (testrunid,
                                                                           time.ctime(starttime),
                                                                           nbtests,
                                                                           nbfailed,
                                                                           softname,
                                                                           clientname,
                                                                           clientuser)
def getMonitorsInfo(db, testid):
    # Return the union of all info about monitors for this test.
    ret = {"args": {}, "results": {}, "extras": {}, "outputfiles": {}}
    monitors = db.getMonitorsIDForTest(testid)

    for mid in monitors or []:
        tid,mtyp,args,results,resperc,extras,outputfiles = db.getFullMonitorInfo(mid)
        ret["args"].update(args)
        ret["results"].update(results)
        ret["extras"].update(extras)
        ret["outputfiles"].update(outputfiles)
    return ret

def getTestName(db, testid):
    _trid, ttype, args, _checks, _resperc, _extras, _outputfiles, parentid, \
            ismon, isscen = db.getFullTestInfo(testid)
    assert not ismon, "Monitors do not have well defined names."

    if parentid and parentid != testid:
        parent_name = getTestName(db, parentid)
    else:
        parent_name = ""

    if "instance-name" in args:
        name = args["instance-name"]
    else:
        name = ttype

    # Top level tests get the media filename prepended.
    media_name = args.get("uri", "").rpartition("/")[-1]
    if media_name and media_name not in parent_name:
        name = "%s.%s" % (media_name, name)

    if parent_name:
        return "%s.%s" % (parent_name, name)
    else:
        return name

def getTestInfo(db, testid):
    data = {}
    trid, ttype, args, checks, resperc, extras, outputfiles, parentid, \
            ismon, isscen = db.getFullTestInfo(testid)
    expl = db.getTestErrorExplanations (testid)

    if resperc is None:
        # test didn't end up in the database
        return {}

    if resperc == 100:
        data["result"] = "pass"
    elif str(dict(checks).get("no-unexpected-failures")) == "1":
        data["result"] = "expected-failure"
    else:
        data["result"] = "fail"

    data["test_case_id"] = getTestName(db, testid)

    monitors = getMonitorsInfo(db, testid)

    # we could gather a log file if there's a known name one
    logfile = None
    if logfile:
        data["log_filename"] = logfile

    if "test-total-duration" in extras:
        data["duration"] = "0d 0s %u000us" % extras["test-total-duration"]

    # Flatten extra information into the attributes dict for debugging.
    attributes = {}
    attributes["success-percentage"] = "%0.1f" % resperc
    for k, v in args.items():
        attributes[("arg." + k)[:MAX_ATTR_LEN]] = str(v)
    checkid = 0
    for k, v in checks:
        checkid = checkid + 1
        attributes[("check." + k)[:MAX_ATTR_LEN]] = str(v)
        if v == 0 and expl and checkid in expl:
          attributes[("check." + k + ".explanation")[:MAX_ATTR_LEN]] = expl[checkid]
    for k, v in extras.items():
        attributes[("extra." + k)[:MAX_ATTR_LEN]] = str(v)
    for k, v in outputfiles.items():
        attributes[("out." + k)[:MAX_ATTR_LEN]] = str(v)
    for k1, subdict in monitors.items():
        for k2, v in subdict.items():
            attributes[("monitor.%s.%s" % (k1, k2))[:MAX_ATTR_LEN]] = str(v)
    data["attributes"] = attributes

    return data

def getTestRun(db, testrunid, failedonly=False, hidescenarios=False):
    # let's output everything !
    cid, starttime, stoptime = db.getTestRun(testrunid)
    softname, clientname, clientuser = db.getClientInfoForTestRun(testrunid)
    environ = db.getEnvironmentForTestRun(testrunid)
    tests = db.getTestsForTestRun(testrunid, withscenarios=not hidescenarios,
                                  failedonly=failedonly)

    test_results = []
    tests_by_name = {}
    for testid in tests:
        data = getTestInfo(db, testid)
        if not data:
            continue
        name = data["test_case_id"]
        tests_by_name[name] = data
        test_results.append(data)

    for name, data in tests_by_name.items():
        if "rerun." in name:
            canonical_name = name.replace("rerun.", "")
            if canonical_name in tests_by_name:
                if tests_by_name[canonical_name]["attributes"]["success-percentage"] == \
                        data["attributes"]["success-percentage"]:
                    test_results.remove(tests_by_name[canonical_name])
                    data["test_case_id"] = canonical_name
                    tests_by_name[canonical_name] = data
                else:
                    warning("%s and %s have different results. " \
                            "Leaving both in report.", canonical_name, name)
            else:
                warning("%s is a rerun, but %s doesn't exist",
                        name, canonical_name)

    for name, data in tests_by_name.items():
        attributes = data.get("attributes", {})
        if "extra.subtest-names" in attributes:
            subtest_names = simplejson.loads(
                    attributes["extra.subtest-names"].replace("'", '"'))
            for subtest_name in subtest_names:
                fullname = "%s.%s" % (name, subtest_name)
                if fullname not in tests_by_name:
                    # It didn't make it into the database. Treat it as
                    # skipped.
                    fake_data = {"test_case_id": fullname, "result": "skip"}
                    tests_by_name[fullname] = fake_data
                    test_results.append(data)

    test_results.sort(key=lambda r: r["test_case_id"])
    return test_results

def printTestRuns(db, testrunids, failedonly=False, hidescenarios=False,
                  indent=None):
    output = {}
    test_results = []

    for testrunid in testrunids:
        result = getTestRun(db, testrunid, failedonly, hidescenarios)
        test_results.extend(result)

    output["test_results"] = test_results

    simplejson.dump(output, sys.stdout, indent=indent, sort_keys=True)
    print # Newline at end of file.

if __name__ == "__main__":
    usage = "usage: %s database [options]" % sys.argv[0]
    parser = ArgumentParser(usage=usage)
    parser.add_argument("-l", "--list", dest="list",
                      help="List the available test runs with summary",
                      action="store_true",
                      default=False)
    parser.add_argument("-a", "--all", dest="all",
                      help="Dump all testruns.",
                      action="store_true",
                      default=False)
    parser.add_argument("-t", "--testrun", dest="testrun",
                      help="Specify a testrun id",
                      type=int,
                      default=-1)
    parser.add_argument("-i", "--indent", dest="indent",
                      help="Indentation for pretty-printed json. "
                           "Default is to use a compact representation.",
                      type=int,
                      default=None)
    parser.add_argument("-f", "--failed", dest="failed",
                      help="Only show failed tests",
                      action="store_true", default=False)
    parser.add_argument("-x", "--hidescenarios", dest="hidescenarios",
                      help="Do not show scenarios",
                      action="store_true", default=False)
    parser.add_argument("-m", "--mysql", dest="usemysql",
                      default=False, action="store_true",
                      help="Connect to a MySQL database for storage")
    parser.add_argument("db", default=None, help="Database")

    options = parser.parse_args(sys.argv[1:])
    if not options.usemysql and not options.db:
        print >> sys.stderr, "You need to specify a database file !"
        parser.print_help()
        sys.exit(1)
    initLogging()
    if options.usemysql:
        try:
            from insanity.storage.mysql import MySQLStorage
        except  ImportError:
            exit(1)
        if len(options.db) > 0:
            kw = MySQLStorage.parse_uri(options.db)
            db = MySQLStorage(async=False, **kw)
        else:
            # use default values
            db = MySQLStorage(async=False)
    else:
        from insanity.storage.sqlite import SQLiteStorage
        db = SQLiteStorage(path=options.db, async=False)
    if options.list:
        # list all available test runs
        testruns = db.listTestRuns()
        for runid in testruns:
            printTestRunInfo(db, runid)
    else:
        testruns = db.listTestRuns()
        if options.testrun and not options.all:
            if not options.testrun in testruns:
                print >> sys.stderr, "Specified testrunid not available !"
                parser.print_help()
                sys.exit(1)
            printTestRuns(db, [options.testrun], options.failed,
                          options.hidescenarios, options.indent)
        else:
            if not testruns:
                print >> sys.stderr, "This file contains no test runs."
                sys.exit(1)
            printTestRuns(db, testruns, options.failed,
                          options.hidescenarios, options.indent)

